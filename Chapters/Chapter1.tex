% Chapter 1

\chapter{Introduction} % Main chapter title

\label{Chapter1:introduction} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%----------------------------------------------------------------------------------------
%1 page: Why you do this topic? Relevancy. What's the problem?
%1-2 page(s): What are you doing?
%1 page: Hence, this thesis tries to answer the following research question(s):
%total 4
%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------


%1 page: Why you do this topic? Relevancy. What's the problem?
%----------------------------------------------------------------------------------------

Scene understanding is long existing and an interesting area for computer vision. It is highly influenced by the binocular stereopsis of the human visual three dimensional (3D) perception. Understanding the structural dependencies is one of the important task for 3D scene understanding and for its reconstruction, which is basically recovering the range and orientation of the surface and object to mimic the humans visual behaviour \cite{barnard1982computational}. This creates multiple opportunities for various multimedia computing applications. Most application requires only the oblique projection of 3D data into two dimensional (2D) plane such as 3D displays, movies, games or structural building representation. But in contrast there are also applications where these 3D depth information could be very important. Applications like augmented and virtual reality for immerse entertainment experience, pose estimation, object tracking, human activity estimation for robotics or autonomous driving systems etc., having a third dimension data (which is depth) is vital. This shows the importance of having depth information for these area of applications. \\

There are many techniques used to derive depth information. Most popular approaches can be categorized into three groups. First, dual camera method \cite{li2009dual}, second, dual pixel method \cite{martinello2015dual, choi2017all} and third sensors based methods \cite{salvi2004pattern}. In extension various methods of estimating depth from focus \cite{grossmann1987depth}, stereo vision \cite{bulthoff1988integration}, and depth from motion \cite{ullman1979interpretation} were also applied. We will discuss more in detail in section \ref{Chapter3:RelatedWork_EarlyApproach}. In this study we mainly focus on sensor based methods, in which there are already some affordable sensing based-technologies were developed. These types of sensors are called structure-light-system (SLS) \cite{salvi2004pattern}, which is based on the projection of structured light \cite{zhang2012microsoft}. Some of the examples for SLS depth sensors are Kinect v1 by Microsoft , Structure Sensor by Occipital, BlasterX Senz3D by Intel Realsense, Leap Motion Sensors by Leap Motion \cite{marin2014hand} and more are available \cite{mal2018sparse}. These devices have proven to have great impact in these areas but they come with a trade off with ease of use at consumer application end. We will discuss more about different SLS depth sensor in the following section \ref{Chapter4:Dataset}. Our study has the focus on depth estimation method based on SLSs, specifically Structure Sensor\footnote{https://structure.io/} by Occipital in the entire work.\\

Meanwhile as we know there is a remarkable interest grown in brain style computation and Artificial neural network (ANNs) is one of its derivative. ANNs have shown great versatility in the field of detection, classification and prediction. ANNs are used for many applications ranging from image processing \cite{guyon1991applications} , audio signal analysis \cite{bourlard1993continuous}, medical \cite{baxt1990use}, business science \cite{widrow1994neural}, music \cite{nadar2019towards} and many more \cite{zhang2000neural}. It  needs a careful processing and considerable domain knowledge for representing raw data into acceptable form for feature learning process. Another import aspect that comes with such brain style computation is hardware limitations towards computational complexity. But in recent days there are significant improvement in the heterogeneous computation \cite{mittal2015survey}. But often times these developments always comes with a difficult trade off choices which has to be evaluated between cost, power consumption and good throughput platforms for ANN's developments and implementations \cite{mittal2019survey}. \\




\section{Motivation}
\begin{figure}[!b]
    \centering
    \includegraphics[width = 12cm]{Figures/ipad.jpg}
    \caption{Structure Sensor}
    \label{fig:Structural_Sensor}
\end{figure}{}

Having a rich scene understanding of indoor spaces can answer various problems related to robotics, human activity recognition etc. also in some of the immersive experience and interactive technologies like  virtual reality and augmented reality applications where positional tracking and scene knowledge is crucial.

Good scene understanding related to depth information for indoor environment might open the doors of opportunities for various multimedia applications where depth information could be very crucial. One such example is \textit{IKEA Place} - an application developed by Apple in partnership with Ikea. \textit{IKEA Place} helps you to measure and place a 3D model of furniture from the Ikea catalog \cite{lehnert2017neue}. The furniture is represented as a 3D model in camera-enabled mobile device in this application \textit{IKEA Place}. One can walk around, bring the piece of furniture in your camera-enabled mobile device and look at it from all sides and see where it can fit in your new house. This is one of the application where depth information could be used. To look at this concept of \textit{IKEA Place} in different perspective, we can recreate the entire indoor space as a 3D model and one can modify each element of their living or working spaces in a personalized fashion. This is one of the example idea where the depth information and 3D reconstruction of a indoor environment concepts can be used, this can be scaled up for various other application as well. Hence the applications of 3D reconstruction of indoor environment can have a wide range of usability. Similarly to the above mentioned application of 3D reconstruction, consumer level usability is also our main focus when applying depth estimation methods.  This is because, even though various efficient methods has been proposed based on the projection of structured light (as discussed in introduction and will be discussed in section \ref{Chapter3:RelatedWork} in detail) are available, the application at the consumer level might be challenging with respect to configuration, portability and background knowledge for usability. As we are discussing at consumer level usability, one of the areas we can look into is portable mobile device cameras. Nowadays, vast majority of cameras distributed in the market are embedded in mobile devices. These cameras have constraints on physical size, mechanical parts and processing capacity \cite{lee2007constraints}. Photographs from portable mobile devices are found to be a new approach for 3D reconstruction besides various traditional sensor based methods \cite{micheletti2015investigating, adan20113d}. In other words 3D image reconstruction from 2D images is our focus and motivation to find a solution in this area. In this context, in our project we utilized Structure Sensor manufactured by company called Occipital which is as SLS for portable mobile devices like Apple IPads as shown in figure \ref{fig:Structural_Sensor}. This comes with an additional hardware installation. Also there have been some efforts made towards low cost and efficient indoor 3D reconstruction using images collected with portable mobile devices or consumer level cameras \cite{ding2019low} but often time these accuracy or quality of these methods always have a trade off with resources like hardware (using SLS, camera quality) or computational efficiency.

In summary, as we understand the importance of depth estimation and its possibilities of remarkable applications in various areas, our motivation in this work is estimation of depth information from a given 2D RGB image information. For this we also want to answer if we can use brain style computational Artificial neural network (ANN) methods because we believe that by implementing a software based method might reduce the complexity at users end but with a trade off of computational power. With the growth of computational power, we believe that it is very much plausible to implement ANN models to consumer level applications in near future.

\section{Topic Description}
\label{Chapeter1:Topic_Description}
\begin{figure}[h]
    \centering
    \includegraphics[width = 12cm]{Figures/idea.png}
    \caption{\textbf{Scope of Research:} The highlighted region in red box in (a) Existing System is replaced by neural network model in (b) Proposed System }
    \label{fig:Proposed_Model}
\end{figure}{}
%1-2 page(s): What are you doing?
This study proposes neural network as an algorithm of depth estimation, more specifically using Convolutions neural networks(CNNs). The solution should define concise and accurate pixel for 3D reconstruction. Therefore, the goal is to achieve high accuracy in identifying the depth, especially boundaries of closer objects since the application is in indoor environment.  Monocular depth estimation is based on exploiting both local properties of texture, gradients, and color, as well as global geometric relations, like relative object placement, and perspective cues \cite{saxena2006learning}. Hence having a global structural understanding of a image is very important and at the same time pixel level details for smaller object is also important in a scene. Often times the indoor environment could be more complex than outdoor because of several smaller objects in a scene. For example in office environment, there could be various physical objects on the table where as in outdoor environment having to deal with relatively larger object dimensions are more common.  

Aim of this project is to deliver a robust method and an architecture for depth image prediction replacing the sensor. As shown in figure \ref{fig:Proposed_Model} (a) existing system for 3D reconstruction rely on hardware based implementation of a SLS which in our case is Structure Sensor integrated with Ipad as seen previously in Figure \ref{fig:Structural_Sensor}. Our existing system uses RBG image from IPad camera and depth information from SLS for 3D reconstruction. Thus our primary goal is to replace the SLS (structure sensor) existing system highlighted in red box as shown in Figure \ref{fig:Proposed_Model} (a) with a neural network as shown in the highlighted box in Figure \ref{fig:Proposed_Model}(b). Our scope of this research is to provide a best working model as similar to the performance of Structure sensor and not 3D reconstruction as seen in the previous Figure \ref{fig:Proposed_Model}(b).  We take advantage of neural network as this has proven to give great results which we will see in details in section \ref{Chapter3:RelatedWork}.


Secondly, existing solutions to depth estimation from a single image usually rely on assumptions in which all the far field depth are mapped to a certain threshold which can result as a wall in 3D reconstruction from 2D. For example, the depth range of Kinect v2 sensor range from 0.5 meters (m) to 4.5m, which means that Kinect has a threshold that maps range above 4.5m to the maximum value of 4.5m that in turns results a wall. \cite{Silberman:ECCV12}. In practical implementation for 3D reconstruction its undesirable for us to have wall. Whereas the possibilities of the the output from SLS or Kinect sensors might give a inaccurate depth and most often times dead pixel - which is also called as holes for range above any threshold (for Kinect v2 is 4.5m) \cite{kinecttof}. Another very important reason for having holes is to get perfect reconstruction - ideally we can repaint the holes by changing the position of camera and not by any post processing methods which gives us better pixel level accuracy than in-painting it, hence rather than approximating the values around holes, it is important for us to have information about these holes. In our work we are also interested to address this problem. We wanted the the network to learn these holes mimicking the SLS along with the relative depth of the scene for efficient regeneration of 3D scene. 

Thirdly, We were also interested to study about the influence and effect of different environment specific models, which means most often times neural network model are designed for a specific task and environment. For example model trained on Kinect sensor for indoor scenes may show performance differences when implemented for Structure Sensor environment due to their camera intrinsic properties. We will discuss in detail about these differences in camera properties in following section \ref{Chapter4:Dataset}. Another reason for this study is because, most of the indoor scene depth estimations are developed based on the dataset created by Kinect sensors, for example NYU\_v2 dataset \cite{silberman11indoor} which We will also discuss more in detail in related work section \ref{Chapter3:RelatedWork}. Thus Structure Sensor and Kinect sensor have different properties with respect to both sensors and cameras (which is used to map the relative color pixel) which brings us to a question how a neural network trained on different dataset influence the depth map suitable for images from IPad.  

These three problems gives us a clear direction to formulates specific questions to be answered in this work which is described below. 


%\section{Research Objective and Research Questions}
%1 page: Hence, this thesis tries to answer the following research question(s):
\subsection{Research Objective}
%\textbf{Research Objective:} 
To achieve a neural network model which can work as similar to the Structure sensor by estimating the depth image from a given 2D image in an indoor environment.

\subsection{Research Questions}
In order to contribute to our above mentioned research objective, we have have structured our research by asking some underlying question which can help us to find the best possible solution to our problem. And we have formulated into these following questions:

\begin{itemize}
    \item \textbf{RQ1}: What is the influence of a neural network model with pre-learnt structural characteristics for depth map prediction?
    \item \textbf{RQ2}: Will there be an Influence of different Camera and sensor properties when tested on cross platform environment?    
    \item \textbf{RQ3}: Can a neural network learn to regenerate the holes from a given monocular RGB image information?
\end{itemize}

We have design out experimental setup in such a way that we can find answers to the above mentioned questions which is described in Section \ref{Chapter5:Experimental_Setup}. First the most important question to answer for us is  \textbf{RQ1}, because various methods in monocular depth estimation have used different encoders which was designed for different task like object detection, classification etc. and acquire common structural feature which in turn used  for depth estimation, we will discuss in detail about such methods in Section \ref{Chapter3:RelatedWork_NNModel}. Also various methods methods where designed for specific task. Our task is to find a best model for specific sensor which is environment and task dependent (in our case the environment is IPad with Structure sensor and for indoor depth estimation task). This leads us to the second question \textbf{RQ2}, if transfer learning approach can give us an improved results, will the model which was task and environment dependent have influence over a new and different environment?. Because in Section \ref{Chapter3:RelatedWork_NNModel} we will discuss that many methods have been investigated based on the Kinect environment for various indoor and outdoor tasks but not specifically to Structure sensor.  By answering these two question we believe to achieve a best solution approach for our task. Then we can answer our novel idea of regeneration of holes with the help of \textbf{RQ3}. More specifically the intuition would be, if a model can regenerate holes to its precision as close to Structure sensor, then we can say the neural network has ability to mimic the Structure Sensor. 

Now we understand the design structure of these question with respect to the two novel proposed ideas (novel model architecture and hole regeneration), is it also important to create new dataset. This is required to answer \textbf{RQ2} and \textbf{RQ3}  because our goal is to achieve a model which is environment and task dependent. For example, existing dataset like Cornell Dataset \cite{3Dscene} , Washington Data V2 \cite{Washington}, Berkeley 3-D Object dataset (B3DO) \cite{Janoch:EECS-2012-85} etc. fail to provide with the holes except NYU\_v2 dataset which contains raw data information we will discuss more about the dataset in detain in section \ref{Chapter4:Dataset}. To give a justified reason for \textbf{RQ3}, we need to generate new dataset to have a common ground for comparison. 

In this initial phase of this research our scope of study is to generate the  depth maps from neural networks after training on similar depth data. All the computation and evaluation were performed and tested with high processing unit which is described in details in Section \ref{Chapter5:HardwarSoftwareDetails}.

Thus, our three main contributions for this work are first, we propose a novel neural network model for depth map generation and compare with state of the art results. Secondly we propose a novel idea of hole regeneration for mimicking the structure sensor. Thirdly, we created a new dataset based on Structural (SLS) Sensor.

