% Chapter Template

\chapter{Basic Principles}
\label{Chapter2:Background} 

In this chapter we will discuss the basic  principles needed for this work. The entire chapter is divided into two sections. In the first chapter we will go through some theory of neural network and basic building blocks  needed for designing a proper neural network for the depth estimation task, most of the concepts are taken from \cite{friedman2001elements}. Second part will be comprising of some basics of depth estimation and camera parameters concepts. Since the area of Artificial Neural Network is very vast we will be focusing on the concepts which was specifically used for this study. 

\section{Artificial Neural Networks}

As we know Artificial Neural Networks (ANNs) are a developed similar to brain style computation consisting of different level of neurons. In other words we can say its a statistical learning or science of learning from given data. There are various types of learning approaches for solving problems
regarding optimization \cite{friedman2001elements}. However, deep learning methodologies have proven to be favorable in ANNs and computer vision tasks such as classifying objects within images and in our we will be using Deep Convolutions Networks. 

To understand the basic types of Neural Network are supervised learning and Unsupervised learning. In general we denote \(X\) as input and \(Y\) as output of a given function. Supervised learning is when there is a labels \(y_{i}\) for each input example \(x_{i}\) where    \(\{(x_{1},y_{1}),(x_{2},y_{2}),...(x_{n},y_{n})\} \in X\) for a learning algorithm satisfying function \(f:X \rightarrow Y\) and output \( \hat{y_{i}} = P (y_{i}|x_{i})\). All labeled classification problems can be categorized under supervised learning such that. For  unsupervised learning clustering or grouping is the detection of similarities for a given input examples \({(x_{1},x_{2},...,x_{n})} \in X\) and joint density \(Pr(X)\)  where as in supervised learning \(Pr(X)\) is of no concern. In supervised learning there is a definite score of success because is \(P(y|y)\) \cite{friedman2001elements}. 

To discuss more about supervised learning with the help of simple binary logistic regression model is given by
\begin{equation} \label{eq1}
    \hat{y_{i}} = x_{i}W + b 
\end{equation}
The problem of this above equation is it linmited to 

%where b \in\mathbb{R}

\begin{equation} \label{eq2}
    e^{\pi i} + 1 = 0
\end{equation}

The basic nuts and bolts of NNs are ...